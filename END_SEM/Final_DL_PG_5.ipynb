{"cells":[{"cell_type":"markdown","metadata":{"id":"VBxsnnpr6ObT"},"source":["#### Program 5:\n","\n","#### Objective:\n","\n","Implement a tiny version of the UNet image segmentation architecture using the PyTorch framework, and train it on the VOCSegmentation dataset.\n","\n","Perform the following steps:\n","\n","- Preprocess data\n","- Define Tiny UNet architecture\n","- Define model train function\n","- Train model"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHQG5ujg6ObW","executionInfo":{"status":"ok","timestamp":1720619563261,"user_tz":-330,"elapsed":104662,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}},"outputId":"585b8db6-1033-4cdb-ed65-4925f6ca3fbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./data/VOCtrainval_11-May-2012.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1999639040/1999639040 [00:54<00:00, 36506049.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n","Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n","Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torchvision.datasets import VOCSegmentation\n","from torch.utils.data import DataLoader, Subset\n","\n","class TinyUNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=21):\n","        super(TinyUNet, self).__init__()\n","        def conv_block(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.ReLU(),\n","                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","                nn.ReLU()\n","            )\n","        self.encoder1 = conv_block(in_channels, 16)\n","        self.encoder2 = conv_block(16, 32)\n","        self.encoder3 = conv_block(32, 64)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.bottleneck = conv_block(64, 128)\n","        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.decoder3 = conv_block(128, 64)\n","        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n","        self.decoder2 = conv_block(64, 32)\n","        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n","        self.decoder1 = conv_block(32, 16)\n","        self.conv_final = nn.Conv2d(16, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool(enc1))\n","        enc3 = self.encoder3(self.pool(enc2))\n","        bottleneck = self.bottleneck(self.pool(enc3))\n","        dec3 = self.upconv3(bottleneck)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","        return self.conv_final(dec1)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","])\n","\n","# Load VOC Segmentation dataset\n","train_dataset = VOCSegmentation(root='./data', year='2012', image_set='train', download=True, transform=transform, target_transform=transform)\n","test_dataset = VOCSegmentation(root='./data', year='2012', image_set='val', download=True, transform=transform, target_transform=transform)\n","\n","train_subset = Subset(train_dataset, range(200))\n","test_subset = Subset(test_dataset, range(50))\n","\n","# Define DataLoader\n","train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_subset, batch_size=10, shuffle=False)\n","\n","model = TinyUNet().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Function to train and evaluate a model\n","def train(model, optimizer, criterion, num_epochs):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data).to(device)\n","            loss = criterion(outputs, target.squeeze(1).long())\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * data.size(0)\n","        avg_train_loss = train_loss / len(train_loader)\n","\n","        model.eval()\n","        test_loss = 0.0\n","        with torch.no_grad():\n","            for data, target in test_loader:\n","                data, target = data.to(device), target.to(device)\n","                outputs = model(data).to(device)\n","                loss = criterion(outputs, target.squeeze(1).long())\n","                test_loss += loss.item() * data.size(0)\n","        avg_test_loss = test_loss / len(test_loader)\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8umFy5E96ObY","executionInfo":{"status":"ok","timestamp":1720619769918,"user_tz":-330,"elapsed":206664,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}},"outputId":"2c488220-b7b5-4ae5-e3c8-ff85a871eb5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 24.8501, Test Loss: 8.2552\n","Epoch [2/10], Train Loss: 5.7716, Test Loss: 3.4715\n","Epoch [3/10], Train Loss: 2.5338, Test Loss: 2.2755\n","Epoch [4/10], Train Loss: 2.1477, Test Loss: 2.0097\n","Epoch [5/10], Train Loss: 2.0166, Test Loss: 2.0877\n","Epoch [6/10], Train Loss: 2.0339, Test Loss: 2.0391\n","Epoch [7/10], Train Loss: 1.9879, Test Loss: 1.9395\n","Epoch [8/10], Train Loss: 1.9593, Test Loss: 1.9254\n","Epoch [9/10], Train Loss: 1.9568, Test Loss: 2.0263\n","Epoch [10/10], Train Loss: 1.9611, Test Loss: 1.9269\n"]}],"source":["\n","train(model, optimizer, criterion, 10)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}