{"cells":[{"cell_type":"markdown","metadata":{"id":"WS-TlE3E3hTK"},"source":["#### Program 3:\n","##### Objective:\n","Write a program using the PyTorch framework to highlight the use of Batch Normalization and Dropout Regularization techniques in CNNs on the CIFAR-10 image dataset.\n","\n","Perform the following steps:\n","- Preprocess data\n","- Define CNN architecture with & without the use of Batch Normalization and Dropout\n","- Define model train function\n","- Train both CNNs using suitable criterion and optimizer"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ZO6urNhe3hTN","executionInfo":{"status":"ok","timestamp":1720618773058,"user_tz":-330,"elapsed":7327,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Subset\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LY4ySQ2s3hTO","executionInfo":{"status":"ok","timestamp":1720618781622,"user_tz":-330,"elapsed":8570,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}},"outputId":"06c6cd47-0702-4bb0-87aa-bbfe32885445"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 48740501.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.dense1 = nn.Linear(64 * 8 * 8, 512)\n","        self.dense2 = nn.Linear(512, 10)\n","        self.relu = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        x = self.relu(x)\n","        x = self.dense2(x)\n","        return x\n","\n","class CNNWithBNDropout(nn.Module):\n","    def __init__(self):\n","        super(CNNWithBNDropout, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.dense1 = nn.Linear(64 * 8 * 8, 512)\n","        self.dense2 = nn.Linear(512, 10)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        x = self.relu(x)\n","        x = self.dense2(x)\n","        x = self.dropout(x)\n","        return x\n","\n","# Data preprocessing and loading\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","train_subset = Subset(train_dataset, range(200))\n","test_subset = Subset(test_dataset, range(50))\n","\n","train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_subset, batch_size=10, shuffle=False)\n","\n","# Function to train and evaluate a model\n","def train(model, optimizer, criterion, num_epochs):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","        for data, target in train_loader:\n","            output = model(data)\n","            loss = criterion(output, target)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","            predicted = torch.argmax(output.data, dim=1)\n","            total_train += target.size(0)\n","            correct_train += (predicted == target).sum().item()\n","        avg_train_loss = train_loss / len(train_loader)\n","        train_acc = 100 * correct_train / total_train\n","\n","        model.eval()\n","        test_loss = 0.0\n","        correct_test = 0\n","        total_test = 0\n","        with torch.no_grad():\n","            for data, target in test_loader:\n","                output = model(data)\n","                loss = criterion(output, target)\n","                test_loss += loss.item()\n","                predicted = torch.argmax(output.data, dim=1)\n","                total_test += target.size(0)\n","                correct_test += (predicted == target).sum().item()\n","        avg_test_loss = test_loss / len(test_loader)\n","        test_acc = 100 * correct_test / total_test\n","\n","        print(f'Epoch: [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_acc:.4f}%, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}%')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWRW_iNJ3hTQ","executionInfo":{"status":"ok","timestamp":1720618799613,"user_tz":-330,"elapsed":17994,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}},"outputId":"5e224ec1-3fd4-4660-8936-bb455c0b54a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [1/10], Train Loss: 2.3141, Train Accuracy: 13.5000%, Test Loss: 2.3018, Test Accuracy: 6.0000%\n","Epoch: [2/10], Train Loss: 2.2600, Train Accuracy: 14.0000%, Test Loss: 2.2744, Test Accuracy: 6.0000%\n","Epoch: [3/10], Train Loss: 2.1210, Train Accuracy: 23.0000%, Test Loss: 2.2544, Test Accuracy: 10.0000%\n","Epoch: [4/10], Train Loss: 1.9539, Train Accuracy: 27.0000%, Test Loss: 2.1527, Test Accuracy: 18.0000%\n","Epoch: [5/10], Train Loss: 1.7908, Train Accuracy: 41.5000%, Test Loss: 1.9042, Test Accuracy: 36.0000%\n","Epoch: [6/10], Train Loss: 1.4651, Train Accuracy: 51.0000%, Test Loss: 1.8328, Test Accuracy: 30.0000%\n","Epoch: [7/10], Train Loss: 1.1462, Train Accuracy: 63.5000%, Test Loss: 2.2093, Test Accuracy: 24.0000%\n","Epoch: [8/10], Train Loss: 0.9314, Train Accuracy: 70.0000%, Test Loss: 2.3066, Test Accuracy: 26.0000%\n","Epoch: [9/10], Train Loss: 0.6946, Train Accuracy: 73.0000%, Test Loss: 2.1470, Test Accuracy: 32.0000%\n","Epoch: [10/10], Train Loss: 0.4464, Train Accuracy: 89.0000%, Test Loss: 2.5651, Test Accuracy: 20.0000%\n","Epoch: [1/10], Train Loss: 3.7324, Train Accuracy: 15.5000%, Test Loss: 2.2132, Test Accuracy: 14.0000%\n","Epoch: [2/10], Train Loss: 2.5432, Train Accuracy: 20.5000%, Test Loss: 2.2129, Test Accuracy: 18.0000%\n","Epoch: [3/10], Train Loss: 2.1086, Train Accuracy: 26.5000%, Test Loss: 2.0355, Test Accuracy: 28.0000%\n","Epoch: [4/10], Train Loss: 1.8725, Train Accuracy: 35.0000%, Test Loss: 1.9131, Test Accuracy: 26.0000%\n","Epoch: [5/10], Train Loss: 1.9910, Train Accuracy: 28.5000%, Test Loss: 1.9862, Test Accuracy: 28.0000%\n","Epoch: [6/10], Train Loss: 1.7550, Train Accuracy: 37.5000%, Test Loss: 1.9632, Test Accuracy: 32.0000%\n","Epoch: [7/10], Train Loss: 1.7093, Train Accuracy: 33.5000%, Test Loss: 2.2795, Test Accuracy: 16.0000%\n","Epoch: [8/10], Train Loss: 1.6620, Train Accuracy: 43.0000%, Test Loss: 2.0758, Test Accuracy: 30.0000%\n","Epoch: [9/10], Train Loss: 1.5856, Train Accuracy: 38.5000%, Test Loss: 2.0238, Test Accuracy: 28.0000%\n","Epoch: [10/10], Train Loss: 1.5032, Train Accuracy: 46.0000%, Test Loss: 2.1987, Test Accuracy: 18.0000%\n"]}],"source":["model1 = SimpleCNN()\n","model2 = CNNWithBNDropout()\n","criterion = nn.CrossEntropyLoss()\n","optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n","optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n","\n","train(model1, optimizer1, criterion, 10)\n","train(model2, optimizer2, criterion, 10)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}