{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyML3Eor416RyVed+Fd3Ekie"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### Program 7:\n","\n","#### Objective:\n","  Implement a Python program using PyTorch to develop an LSTM-based model.\n","\n","Tasks:\n","  - Define an LSTM classifier with embedding, LSTM, and fully connected layers. Adjust the\n","    model to handle a hypothetical vocabulary size and embedding dimensions.\n","  - Train the LSTM model using the CrossEntropyLoss and Adam optimizer, monitoring the loss\n","    over epochs.\n"],"metadata":{"id":"uiuDzs2D_k_e"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qajnTqVR-e3L","executionInfo":{"status":"ok","timestamp":1720621051539,"user_tz":-330,"elapsed":12145,"user":{"displayName":"JESWIN M S","userId":"17267416076578851849"}},"outputId":"e5608346-254f-4b54-cbda-4040a6c0b162"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.7027\n","Epoch 2, Loss: 0.6702\n","Epoch 3, Loss: 0.6407\n","Epoch 4, Loss: 0.5980\n","Epoch 5, Loss: 0.5247\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Generate random data and labels\n","data = torch.randint(0, 1000, (100, 10))\n","labels = torch.randint(0, 2, (100,))\n","\n","# Create dataset and dataloader\n","dataset = TensorDataset(data, labels)\n","loader = DataLoader(dataset, batch_size=10, shuffle=True)\n","\n","# Define LSTMClassifier\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n","        super(LSTMClassifier, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        _, (hidden, _) = self.lstm(x)\n","        return self.fc(hidden.squeeze(0))\n","\n","# Instantiate model, criterion, and optimizer\n","model = LSTMClassifier(1000, 50, 100, 2)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","# Define training function\n","def train(n_epochs):\n","    for epoch in range(n_epochs):\n","        model.train()\n","        train_loss = 0.0\n","\n","        for data, tgts in loader:\n","            outputs = model(data)\n","            loss = criterion(outputs, tgts)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        avg_train_loss = train_loss / len(loader)\n","        print(f\"Epoch {epoch+1}, Loss: {avg_train_loss:.4f}\")\n","\n","# Train the model for 5 epochs\n","train(5)\n"]}]}